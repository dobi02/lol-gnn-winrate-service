import os
import sys
import json
import shutil
import torch
import mlflow.tracking
from torch_geometric.data import Batch, HeteroData


class LoLPredictor:
    def __init__(self, run_id: str, device: str = "cpu"):
        self.device = torch.device(device)
        client = mlflow.tracking.MlflowClient()

        # ---------------------------------------------------------
        # 1. Artifact ìºì‹œ í™•ì¸ -> ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
        # ---------------------------------------------------------
        cache_root = os.getenv("MLFLOW_ARTIFACT_CACHE_DIR", "/tmp/mlflow-artifacts")
        run_cache_root = os.path.join(cache_root, run_id)
        os.makedirs(run_cache_root, exist_ok=True)

        manifest_path = os.path.join(run_cache_root, "manifest.json")
        cached_local_path = ""
        if os.path.exists(manifest_path):
            try:
                with open(manifest_path, "r", encoding="utf-8") as f:
                    manifest = json.load(f)
                    cached_local_path = manifest.get("local_path", "")
            except Exception:
                cached_local_path = ""

        def _is_valid_artifact_dir(path: str) -> bool:
            if not path:
                return False
            config_ok = (
                os.path.exists(os.path.join(path, "config", "config.json"))
                or os.path.exists(os.path.join(path, "config.json"))
            )
            weight_ok = os.path.exists(os.path.join(path, "model", "data", "model.pth"))
            code_ok = os.path.isdir(os.path.join(path, "code"))
            return config_ok and weight_ok and code_ok

        local_path = ""
        candidate_paths = [
            cached_local_path,
            run_cache_root,
            os.path.join(run_cache_root, "artifacts"),
        ]
        for candidate in candidate_paths:
            if _is_valid_artifact_dir(candidate):
                local_path = candidate
                print(f"â™»ï¸ MLflow artifact cache hit: {local_path}")
                break

        if not local_path:
            local_path = client.download_artifacts(run_id, path="", dst_path=run_cache_root)
            with open(manifest_path, "w", encoding="utf-8") as f:
                json.dump({"run_id": run_id, "local_path": local_path}, f)
            print(f"â¬‡ï¸ MLflow artifact downloaded: {local_path}")

        # ìµœê·¼ 1ê°œ(run_id)ë§Œ ìœ ì§€: í˜„ì¬ run_idë¥¼ ì œì™¸í•œ ìºì‹œ ë””ë ‰í„°ë¦¬ ì •ë¦¬
        for entry in os.listdir(cache_root):
            entry_path = os.path.join(cache_root, entry)
            if entry == run_id:
                continue
            if os.path.isdir(entry_path):
                try:
                    shutil.rmtree(entry_path)
                    print(f"ğŸ§¹ Removed old MLflow cache run: {entry}")
                except Exception as e:
                    print(f"âš ï¸ Failed to remove old cache run {entry}: {e}")

        code_path = os.path.join(local_path, "code")

        # ---------------------------------------------------------
        # 2. ë™ì  ì„í¬íŠ¸ (Dynamic Import)
        # ---------------------------------------------------------
        # model.pyì™€ model_utils.pyê°€ ìˆëŠ” ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
        if code_path not in sys.path:
            sys.path.append(code_path)

        try:
            # model.pyì—ì„œ LoLGNN í´ë˜ìŠ¤ ë¡œë“œ
            from model import LoLGNN
        except ImportError as e:
            raise RuntimeError(f"ëª¨ë¸ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. model_utils.py ë“±ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")

        # ---------------------------------------------------------
        # 3. ëª¨ë¸ ì´ˆê¸°í™”
        # ---------------------------------------------------------
        config_path = os.path.join(local_path, "config", "config.json")
        try:
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        except FileNotFoundError:
            # ê²½ë¡œê°€ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆë¹„ ê²½ë¡œ (artifacts êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            config_path = os.path.join(local_path, "config.json")
            with open(config_path, 'r') as f:
                self.config = json.load(f)

        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.model = LoLGNN(self.config)

        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        weight_path = os.path.join(local_path, "model", "data", "model.pth")
        self.model.load_state_dict(torch.load(weight_path, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()

        print("âœ… MLflowì—ì„œ ì½”ë“œì™€ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    def predict_team100_win_rate(self, data: HeteroData) -> float:
        """
        APIì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.
        model.pyì˜ forward(x_dict, edge_index_dict, batch_dict) ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶° ë°ì´í„°ë¥¼ ê°€ê³µí•©ë‹ˆë‹¤.
        """
        if self.model is None:
            return 0.5

        # 1. Device ì´ë™
        data = data.to(self.device)

        # 2. Batch ê°ì²´ ìƒì„± (ë‹¨ì¼ ê·¸ë˜í”„ë¼ë„ Batchë¡œ ê°ì‹¸ì•¼ batch vectorê°€ ìƒì„±ë¨)
        batch = Batch.from_data_list([data])

        # 3. ì¸ì ì¤€ë¹„ (model.pyì˜ ìš”êµ¬ì‚¬í•­)
        # HeteroData Batch ê°ì²´ëŠ” x_dict, edge_index_dict ì†ì„±ì„ ê°€ì§‘ë‹ˆë‹¤.
        x_dict = batch.x_dict
        edge_index_dict = batch.edge_index_dict

        # â˜… ì¤‘ìš”: batch_dict ìƒì„± â˜…
        # model.pyì˜ global_mean_pool(x_dict['player'], batch_dict['player'])ë¥¼ ìœ„í•´ í•„ìš”
        batch_dict = {}
        for node_type in batch.node_types:
            batch_dict[node_type] = batch[node_type].batch

        # 4. ì¶”ë¡ 
        with torch.no_grad():
            # forward(self, x_dict, edge_index_dict, batch_dict) í˜¸ì¶œ
            logits = self.model(x_dict, edge_index_dict, batch_dict)
            prob = torch.sigmoid(logits).item()

        return prob
